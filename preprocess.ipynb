{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from lib.his_preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for target_var in [\"2m_temperature\", 'geopotential']:\n",
    "    if target_var == '2m_temperature':\n",
    "        p_1 = sorted(glob.glob('/data/GC_output/2021-06-21/GC_???????????_global_scale*.nc'))\n",
    "        p_2 = sorted(glob.glob('/data/GC_output/2021-06-21/GC_00100000000_*_scale*.nc'))\n",
    "        p_3 = sorted(glob.glob('/data/GC_output/2021-06-21/GC_11011111111_*_scale*.nc'))\n",
    "\n",
    "    elif target_var == 'geopotential':\n",
    "        p_1 = sorted(glob.glob('/data/GC_output/2021-06-21/GC_???????????_global_scale*.nc'))\n",
    "        p_2 = sorted(glob.glob('/data/GC_output/2021-06-21/GC_00000100000_*_scale*.nc'))\n",
    "        p_3 = sorted(glob.glob('/data/GC_output/2021-06-21/GC_11111011111_*_scale*.nc'))  \n",
    "\n",
    "    # Assign base colors for each partition\n",
    "    partition_colors = {\n",
    "        'p_1': 'blue',\n",
    "        'p_2': 'green',\n",
    "        'p_3': 'red',\n",
    "        'p_4': 'purple'\n",
    "    }\n",
    "\n",
    "    # Function to extract perturbation type and value from filename\n",
    "    def extract_perturbation_info(filename):\n",
    "        match = re.search(r'_([01][01][01][01][01][01][01][01][01][01][01])_(.*?)_(scale|wipeout)_([\\d.eE+-]+)\\.nc$', filename)\n",
    "        if match:\n",
    "            var=match.group(1)\n",
    "            region=match.group(2)\n",
    "            perturb_type = match.group(3)\n",
    "            value = match.group(4)\n",
    "            return f\"{value}_{region}_{var}\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Collect perturbation files with labels and colors\n",
    "    perturb_files = []\n",
    "    for partition_name, partition_files in zip(['p_1', 'p_2', 'p_3'], [p_1, p_2, p_3]):\n",
    "    # for partition_name, partition_files in zip(['p_4'], [p_4]):\n",
    "        base_color = partition_colors[partition_name]\n",
    "        num_files = len(partition_files)\n",
    "        # Generate different shades of the base color\n",
    "        colors = sns.light_palette(base_color, n_colors=num_files + 2)[1:-1]\n",
    "        for i, file in enumerate(partition_files):\n",
    "            perturb_info = extract_perturbation_info(file)\n",
    "            if perturb_info:\n",
    "                label = f\"{partition_name} {perturb_info}\"\n",
    "                color = colors[i % len(colors)]\n",
    "                perturb_files.append((label, color, file))\n",
    "\n",
    "    perturb_datasets = []\n",
    "\n",
    "    def process_file(file_info):\n",
    "        label, color, file = file_info\n",
    "        dataset = weighted_mean(preprocess_GC(xr.open_dataset(file), target_var))\n",
    "        return (label, color, dataset)\n",
    "\n",
    "    with Pool(processes=35) as pool:\n",
    "        perturb_datasets = pool.map(process_file, perturb_files)\n",
    "\n",
    "    def piping(dataset:xr.Dataset, target_var):\n",
    "        return weighted_mean(preprocess_nwp(dataset, target_var))\n",
    "\n",
    "    from functools import partial\n",
    "    pipe = partial(piping, target_var = target_var)\n",
    "\n",
    "    if target_var == '2m_temperature':\n",
    "        files = sorted(glob.glob('/geodata2/S2S/ECMWF_Perturbed/Dailyaveraged/t2m/nc/*/Temperature2m_2021-06-21.nc'))\n",
    "\n",
    "    elif target_var == 'geopotential':\n",
    "        files = sorted(glob.glob('/geodata2/S2S/ECMWF_Perturbed/InstantaneousAccumulated/z/nc/*/Z_2021-06-21.nc'))\n",
    "\n",
    "    files = [f for f in files if int(f.split('/')[-2]) <= 24 * 7]\n",
    "    nwp = xr.open_mfdataset(\n",
    "        files,\n",
    "        combine='by_coords',\n",
    "        preprocess=pipe\n",
    "    )\n",
    "    if target_var == \"2m_temperature\":\n",
    "        nwp = nwp.rename({\"2t\":\"2m_temperature\"})\n",
    "\n",
    "    nwp = nwp.compute()\n",
    "    df = nwp[target_var].to_dataframe().reset_index()\n",
    "    \n",
    "    if target_var == '2m_temperature':\n",
    "        nwp.to_netcdf('/data/GC_output/analysis/nwp_t2m_GlobAvg.nc')\n",
    "        with open('/data/GC_output/analysis/GC_t2m_GlobAvg.pkl', 'wb') as f:\n",
    "            pickle.dump(perturb_datasets, f)\n",
    "\n",
    "    elif target_var == 'geopotential':\n",
    "        nwp.to_netcdf('/data/GC_output/analysis/nwp_z500_GlobAvg.nc')\n",
    "        with open('/data/GC_output/analysis/GC_z500_GlobAvg.pkl', 'wb') as f:\n",
    "            pickle.dump(perturb_datasets, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw NWP has useless dimention.... to handle that.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from lib.his_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "48\n",
      "72\n",
      "96\n",
      "120\n",
      "144\n",
      "168\n",
      "192\n",
      "216\n",
      "240\n",
      "264\n",
      "288\n",
      "312\n",
      "336\n",
      "360\n",
      "384\n",
      "408\n",
      "432\n",
      "456\n",
      "480\n",
      "504\n",
      "528\n",
      "552\n",
      "576\n",
      "600\n",
      "624\n",
      "648\n",
      "672\n",
      "696\n",
      "720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiskim1/.conda/envs/hiskim1_gencast/lib/python3.11/site-packages/zarr/api/asynchronous.py:197: UserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for target_var in [\"2m_temperature\"]:\n",
    "    def piping(dataset: xr.Dataset, target_var):\n",
    "        return weighted_mean(preprocess_nwp(dataset, target_var))\n",
    "\n",
    "    from functools import partial\n",
    "    pipe = partial(piping, target_var=target_var)\n",
    "\n",
    "    if target_var == '2m_temperature':\n",
    "        files = glob.glob('/geodata2/S2S/ECMWF_Perturbed/Dailyaveraged/t2m/nc/*/Temperature2m_2021-06-21.nc')\n",
    "        \n",
    "        # 경로에서 숫자 부분을 추출하여 정렬\n",
    "        files = sorted(files, key=lambda x: int(x.split('/')[-2]))\n",
    "\n",
    "    elif target_var == 'geopotential':\n",
    "        files = glob.glob('/geodata2/S2S/ECMWF_Perturbed/InstantaneousAccumulated/z/nc/*/Z_2021-06-21.nc')\n",
    "        files = sorted(files, key=lambda x: int(x.split('/')[-2]))\n",
    "\n",
    "    # 7일 이하 데이터만 필터링\n",
    "    files = [f for f in files if int(f.split('/')[-2]) <= 24 * 30]\n",
    "\n",
    "    # 정렬된 순서 확인\n",
    "    for f in files:\n",
    "        print(f.split('/')[-2])  # 디버깅용\n",
    "\n",
    "    # 순서대로 데이터셋 생성\n",
    "    datasets = [preprocess_nwp(xr.open_dataset(f), target_var) for f in files]\n",
    "    \n",
    "    # date 차원으로 병합할 때 순서 보장\n",
    "    nwp = xr.concat(datasets, dim=\"date\")\n",
    "    \n",
    "    # 필요하다면 date 차원 정렬\n",
    "    nwp = nwp.sortby('date')\n",
    "\n",
    "    if target_var == \"2m_temperature\":\n",
    "        nwp = nwp.rename({\"2t\": \"2m_temperature\"})\n",
    "\n",
    "    nwp = nwp.compute()\n",
    "    df = nwp[target_var].to_dataframe().reset_index()\n",
    "\n",
    "    if target_var == '2m_temperature':\n",
    "        nwp.to_zarr('/data/GC_output/analysis/30_nwp_t2m_Globraw.zarr')\n",
    "    elif target_var == 'geopotential':\n",
    "        nwp.to_netcdf('/data/GC_output/analysis/percent/10_nwp_z500_Globraw.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiskim1/.conda/envs/hiskim1_gencast/lib/python3.11/site-packages/zarr/api/asynchronous.py:197: UserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x153496080ee0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def piping(dataset:xr.Dataset, target_var):\n",
    "    return weighted_mean(preprocess_nwp(dataset, target_var))\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "target_var = \"2m_temperature\"\n",
    "\n",
    "pipe = partial(piping, target_var = target_var)\n",
    "\n",
    "files = sorted(glob.glob('/geodata2/S2S/ECMWF_Perturbed/Dailyaveraged/t2m/nc/*/Temperature2m_2021-06-21.nc'))\n",
    "\n",
    "files = [f for f in files if int(f.split('/')[-2]) <= 24 * 30]\n",
    "\n",
    "nwp = xr.open_mfdataset(\n",
    "    files,\n",
    "    combine='by_coords',\n",
    "    preprocess=pipe\n",
    ")\n",
    "\n",
    "if target_var == \"2m_temperature\":\n",
    "    nwp = nwp.rename({\"2t\":\"2m_temperature\"})\n",
    "\n",
    "nwp = nwp.compute()\n",
    "\n",
    "df = nwp[target_var].to_dataframe().reset_index()\n",
    "\n",
    "nwp.squeeze().to_zarr('/data/GC_output/analysis/30_nwp_t2m_GlobAvg.zarr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiskim1_gencast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
